epoch	train loss	eval_loss	eval global accuracy	micro_f1_score	macro_f1_score	learning_rate
0	601555.6884765625	1243.5173095703126	94.51090781140043	0.9451090781140042	0.763807381904951	5e-05
1	727830.4774780273	1172.108837890625	94.69980369643321	0.946998036964332	0.7819970970843875	5e-05
2	830154.3141326904	992.473779296875	95.95170191488573	0.9595170191488573	0.8300488481703263	5e-05
3	914908.4640655518	1062.0464111328124	95.56650246305419	0.9556650246305419	0.8382185670921288	5e-05
4	986724.5508117676	1041.627197265625	95.86280973369384	0.9586280973369384	0.8457386631209224	5e-05
5	1049272.6954040527	1085.067236328125	95.97022111930072	0.9597022111930071	0.8481709382555834	5e-05
6	1094914.6470489502	813.6754516601562	96.11837475462055	0.9611837475462054	0.8520593544142375	5e-05
6	1121924.0813446045	902.4843872070312	96.1517093225675	0.961517093225675	0.8983852736971838	5e-05
7	1144405.5639038086	1034.2579223632813	95.85910589281085	0.9585910589281085	0.8844501198186311	5e-05
8	1165665.3141784668	1000.9612426757812	95.86651357457684	0.9586651357457684	0.8947900340953429	5e-05
9	1186772.8609466553	1010.1495727539062	95.87392125634283	0.9587392125634283	0.8847081793919771	5e-05
10	1207172.1234283447	995.44951171875	96.08874402755657	0.9608874402755657	0.8786296320917679	5e-05
11	1227815.3230285645	1009.2274780273438	95.99985184636468	0.9599985184636468	0.8480594254204353	5e-05
12	1248642.9371948242	1017.870556640625	95.8998481425238	0.958998481425238	0.8713944438277352	5e-05
12	1270713.493927002	963.8285339355468	96.04800177784362	0.9604800177784363	0.8926111111652052	5e-05
13	1291127.0782318115	1014.8457763671875	95.96651727841773	0.9596651727841772	0.851975521888885	5e-05
14	1311144.7916259766	978.37822265625	95.96651727841773	0.9596651727841772	0.8917144232438022	5e-05
15	1331146.2507629395	1024.5333862304688	95.87392125634283	0.9587392125634283	0.8811620767839927	5e-05
epoch	train loss	eval_loss	eval global accuracy	micro_f1_score	macro_f1_score	learning_rate
0	315833.73205566406	1031.2288940429687	94.03681617837698	0.9403681617837698	0.786987548939718	5e-05
1	417134.3419494629	896.7917724609375	94.77017667321012	0.9477017667321012	0.8152177646731517	5e-05
2	495028.6218109131	828.9314086914062	95.44057187303234	0.9544057187303233	0.8541833514809553	5e-05
3	556261.8224029541	839.2451293945312	95.67391384866106	0.9567391384866106	0.8693359215626693	5e-05
4	605577.1768035889	836.911376953125	95.91466350605577	0.9591466350605578	0.8814238605996905	5e-05
5	644702.4732513428	938.3357604980469	95.729471461906	0.95729471461906	0.8755131545709371	5e-05
6	682118.3214874268	874.9359619140625	95.85910589281085	0.9585910589281085	0.8400767760692609	5e-05
6	719959.6994171143	858.2345947265625	96.08504018667358	0.9608504018667358	0.8867798002259009	5e-05
7	750715.9188842773	958.369189453125	95.79243675691693	0.9579243675691692	0.8796578808385422	5e-05
8	780706.8794555664	985.2841918945312	95.86651357457684	0.9586651357457684	0.8424672857207065	5e-05
9	809970.2768707275	945.5392456054688	95.82206748398089	0.9582206748398089	0.8799752001275867	5e-05
10	838565.3983306885	994.5809814453125	95.87762509722582	0.9587762509722583	0.8752744006005965	5e-05
11	867654.7966918945	986.2845092773438	95.6368754398311	0.956368754398311	0.8768245405011292	5e-05
12	897108.2628631592	984.2683715820312	95.6405792807141	0.956405792807141	0.8731647457623876	5e-05
12	927298.2748413086	912.9149169921875	95.96281343753472	0.9596281343753472	0.8778868699902334	5e-05
13	956560.4648284912	978.0922241210938	95.75539834808697	0.9575539834808696	0.8833786923269776	5e-05
14	984758.371963501	955.5525146484375	95.64798696248009	0.9564798696248009	0.871088066206899	5e-05
15	1013088.0146026611	990.7240844726563	95.725767621023	0.9572576762102301	0.8784974696945874	5e-05
epoch	train loss	eval_loss	eval global accuracy	micro_f1_score	macro_f1_score	learning_rate
0	637226.6071777344	1047.20966796875	93.09943034697048	0.9309943034697048	0.7483187399328834	5e-05
1	743121.8087615967	895.6444458007812	93.68203003625065	0.9368203003625065	0.8058524033141556	5e-05
2	823338.5590057373	813.972900390625	94.73070947695494	0.9473070947695494	0.8497755416450978	5e-05
3	886902.9184112549	853.3829833984375	94.51924736751252	0.9451924736751252	0.8648392744885627	5e-05
4	937257.1422576904	804.7737060546875	95.49887795615398	0.9549887795615398	0.8858032508676068	5e-05
5	977717.188293457	869.3159545898437	95.1838425686173	0.9518384256861729	0.8710278294202308	5e-05
6	1016350.9509887695	866.1921630859375	95.0414293112377	0.950414293112377	0.8724261285078594	5e-05
6	1055179.48828125	822.521142578125	95.38235801829795	0.9538235801829794	0.8907401778975083	5e-05
7	1087174.313659668	930.638330078125	95.0586915242534	0.950586915242534	0.8654901100667256	5e-05
8	1117933.1128845215	962.7132080078125	94.9939582254445	0.949939582254445	0.875611138984635	5e-05
9	1147803.478149414	957.9702514648437	95.05006041774556	0.9505006041774555	0.8793743495822245	5e-05
10	1177258.327545166	942.39501953125	95.1363714828241	0.951363714828241	0.8743058738785886	5e-05
11	1207423.6405944824	912.0475341796875	95.2960469532194	0.952960469532194	0.8813325874247088	5e-05
12	1237999.2619628906	898.5180786132812	95.1363714828241	0.951363714828241	0.8356236312003166	5e-05
12	1269297.1418914795	875.5379028320312	95.3262558259969	0.953262558259969	0.879184131756901	5e-05
13	1299022.9620819092	958.6354248046875	95.17521146210944	0.9517521146210944	0.8737522748337512	5e-05
14	1328472.359588623	943.0292114257812	94.89038494735026	0.9489038494735025	0.8722073081585694	5e-05
15	1357929.5061645508	975.9776000976562	95.08026929052305	0.9508026929052305	0.8772231462570592	5e-05
